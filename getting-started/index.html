



<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Pengetian K-Means Clustering, K-Nearest Neighbor dan Decision Tree">
      
      
        <link rel="canonical" href="https://MahrusSholeh.github.io/170441100023-KMeansClustering-KNN&decisiontree/getting-started/">
      
      
        <meta name="author" content="Mahrus Sholeh">
      
      
        <meta name="lang:clipboard.copy" content="Copy to clipboard">
      
        <meta name="lang:clipboard.copied" content="Copied to clipboard">
      
        <meta name="lang:search.language" content="en">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="No matching documents">
      
        <meta name="lang:search.result.one" content="1 matching document">
      
        <meta name="lang:search.result.other" content="# matching documents">
      
        <meta name="lang:search.tokenizer" content="[\s\-]+">
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.2.0">
    
    
      
        <title>Penjelasan tentang K-Nearest Neighbor - Implementasi K-Means Clustering, K-Nearest Neighbor dan Decision Tree</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/application.750b69bd.css">
      
        <link rel="stylesheet" href="../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#3f51b5">
      
    
    
      <script src="../assets/javascripts/modernizr.74668098.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#implementasi-data-k-nearest-neighbor" tabindex="1" class="md-skip">
        Skip to content
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://MahrusSholeh.github.io/170441100023-KMeansClustering-KNN&decisiontree/" title="Implementasi K-Means Clustering, K-Nearest Neighbor dan Decision Tree" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Implementasi K-Means Clustering, K-Nearest Neighbor dan Decision Tree
            </span>
            <span class="md-header-nav__topic">
              Penjelasan tentang K-Nearest Neighbor
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/MahrusSholeh/170441100023-KMeansClustering-KNN&decisiontree" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    170441100023-KMeansClustering-KNN
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

<nav class="md-tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href=".." title="Penjelasan tentang K-Means Clustering" class="md-tabs__link md-tabs__link--active">
        Penjelasan tentang K-Means Clustering
      </a>
    
  </li>

      
        
      
        
      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="https://MahrusSholeh.github.io/170441100023-KMeansClustering-KNN&decisiontree/" title="Implementasi K-Means Clustering, K-Nearest Neighbor dan Decision Tree" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Implementasi K-Means Clustering, K-Nearest Neighbor dan Decision Tree
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/MahrusSholeh/170441100023-KMeansClustering-KNN&decisiontree" title="Go to repository" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    170441100023-KMeansClustering-KNN
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href=".." title="Penjelasan tentang K-Means Clustering" class="md-nav__link">
      Penjelasan tentang K-Means Clustering
    </a>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        Penjelasan tentang K-Nearest Neighbor
      </label>
    
    <a href="./" title="Penjelasan tentang K-Nearest Neighbor" class="md-nav__link md-nav__link--active">
      Penjelasan tentang K-Nearest Neighbor
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pengertian-tentang-k-nearest-neighbor" title="Pengertian tentang K-Nearest Neighbor" class="md-nav__link">
    Pengertian tentang K-Nearest Neighbor
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cara-kerja-algoritma-k-nearest-neighbors-knn" title="Cara Kerja Algoritma K-Nearest Neighbors (KNN)" class="md-nav__link">
    Cara Kerja Algoritma K-Nearest Neighbors (KNN)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#klasifikasi-terdekat-nearest-neighbor-classification" title="Klasifikasi Terdekat (Nearest Neighbor Classification)" class="md-nav__link">
    Klasifikasi Terdekat (Nearest Neighbor Classification)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algoritma-k-nearest-neighbor" title="Algoritma K-Nearest Neighbor" class="md-nav__link">
    Algoritma K-Nearest Neighbor
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kelebihan-dan-kekurangan-dari-algoritma-k-nn" title="Kelebihan dan Kekurangan dari Algoritma K-NN" class="md-nav__link">
    Kelebihan dan Kekurangan dari Algoritma K-NN
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../customization/" title="Penjelasan tentang Decision Tree Classifier" class="md-nav__link">
      Penjelasan tentang Decision Tree Classifier
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pengertian-tentang-k-nearest-neighbor" title="Pengertian tentang K-Nearest Neighbor" class="md-nav__link">
    Pengertian tentang K-Nearest Neighbor
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#cara-kerja-algoritma-k-nearest-neighbors-knn" title="Cara Kerja Algoritma K-Nearest Neighbors (KNN)" class="md-nav__link">
    Cara Kerja Algoritma K-Nearest Neighbors (KNN)
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#klasifikasi-terdekat-nearest-neighbor-classification" title="Klasifikasi Terdekat (Nearest Neighbor Classification)" class="md-nav__link">
    Klasifikasi Terdekat (Nearest Neighbor Classification)
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#algoritma-k-nearest-neighbor" title="Algoritma K-Nearest Neighbor" class="md-nav__link">
    Algoritma K-Nearest Neighbor
  </a>
  
    <nav class="md-nav">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#kelebihan-dan-kekurangan-dari-algoritma-k-nn" title="Kelebihan dan Kekurangan dari Algoritma K-NN" class="md-nav__link">
    Kelebihan dan Kekurangan dari Algoritma K-NN
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="implementasi-data-k-nearest-neighbor">Implementasi data K-Nearest Neighbor<a class="headerlink" href="#implementasi-data-k-nearest-neighbor" title="Permanent link">&para;</a></h1>
<h2 id="pengertian-tentang-k-nearest-neighbor">Pengertian tentang K-Nearest Neighbor<a class="headerlink" href="#pengertian-tentang-k-nearest-neighbor" title="Permanent link">&para;</a></h2>
<p><img alt="" src="../assets/images/K-Nearest-Neighbors.png" /></p>
<p><strong>K-nearest neighbors</strong>  adalah algoritma yang berfungsi untuk melakukan klasifikasi suatu data berdasarkan data pembelajaran (<em>train data sets</em>), yang diambil dari k tetangga terdekatnya (<em>nearest neighbors</em>). Dengan k merupakan banyaknya tetangga terdekat.</p>
<h4 id="cara-kerja-algoritma-k-nearest-neighbors-knn"><strong>Cara Kerja Algoritma K-Nearest Neighbors (KNN)</strong><a class="headerlink" href="#cara-kerja-algoritma-k-nearest-neighbors-knn" title="Permanent link">&para;</a></h4>
<p><strong>K-nearest neighbors</strong> melakukan klasifikasi dengan proyeksi data pembelajaran pada ruang berdimensi banyak. Ruang ini dibagi menjadi bagian-bagian yang merepresentasikan kriteria data pembelajaran. Setiap data pembelajaran direpresentasikan menjadi titik-titik <strong><em>c</em></strong> pada ruang dimensi banyak.</p>
<h5 id="klasifikasi-terdekat-nearest-neighbor-classification"><strong>Klasifikasi Terdekat (Nearest Neighbor Classification)</strong><a class="headerlink" href="#klasifikasi-terdekat-nearest-neighbor-classification" title="Permanent link">&para;</a></h5>
<p><strong>Data baru</strong> yang diklasifikasi selanjutnya diproyeksikan pada ruang dimensi banyak yang telah memuat titik-titik c data pembelajaran. Proses klasifikasi dilakukan dengan mencari titik <strong>c</strong> terdekat dari <strong>c-baru</strong> (<em>nearest neighbor</em>)<em>.</em> Teknik pencarian tetangga terdekat yang umum dilakukan dengan menggunakan formula jarak euclidean*.* Berikut beberapa formula yang digunakan dalam algoritma knn.</p>
<h2 id="algoritma-k-nearest-neighbor">Algoritma K-Nearest Neighbor<a class="headerlink" href="#algoritma-k-nearest-neighbor" title="Permanent link">&para;</a></h2>
<h4 id="kelebihan-dan-kekurangan-dari-algoritma-k-nn"><strong>Kelebihan dan Kekurangan dari Algoritma K-NN</strong><a class="headerlink" href="#kelebihan-dan-kekurangan-dari-algoritma-k-nn" title="Permanent link">&para;</a></h4>
<p><strong>Kelebihan :</strong></p>
<p>Sangat nonlinear</p>
<ul>
<li>KNN merupakan salah satu algoritma (model) pembelajaran mesin yang bersifat nonparametrik. Pembahasan mengenai <strong>model parametrik</strong> dan model <strong>nonparametrik</strong> bisa menjadi artikel sendiri, namun secara singkat, definisi model nonparametrik adalah model yang tidak mengasumsikan apa-apa mengenai distribusi instance di dalam dataset. Model nonparametrik biasanya lebih sulit diinterpretasikan, namun salah satu kelebihannya adalah garis keputusan kelas yang dihasilkan model tersebut bisa jadi sangat fleksibel dan nonlinear.</li>
</ul>
<p>Mudah dipahami dan diimplementasikan</p>
<ul>
<li>Dari paparan yang diberikan dan penjelasan cara menghitung jarak dalam artikel ini, cukup jelas bahwa algoritma kNN mudah dipahami dan juga mudah dimplementasikan. Untuk mengklasifikasi instance x menggunakan kNN, kita cukup mendefinisikan fungsi untuk menghitung jarak antar-instance, menghitung jarak x dengan semua instance lainnya berdasarkan fungsi tersebut, dan menentukan kelas x sebagai kelas yang paling banyak muncul dalam k instance terdekat.</li>
</ul>
<p><strong>Kekurangan :</strong></p>
<ul>
<li>
<p><strong>Perlu menunjukkan parameter K (jumlah tetangga terdekat)</strong></p>
</li>
<li>
<p><strong>Tidak menangani nilai hilang (missing value) secara implisit</strong></p>
</li>
<li>
<p>Jika terdapat nilai hilang pada satu atau lebih variabel dari suatu instance, perhitungan jarak instance tersebut dengan instance lainnya menjadi tidak terdefinisi. Bagaimana coba, menghitung jarak dalam ruang 3-dimensi jika salah satu dimensi hilang? Karenanya, sebelum menerapkan kNN kerap dilakukan <strong>imputasi</strong> untuk mengisi nilai-nilai hilang yang ada pada dataset. Contoh teknik imputasi yang paling umum adalah mengisi nilai hilang pada suatu variabel dengan nilai rata-rata variabel tersebut (mean imputation).</p>
</li>
<li>
<p><strong>Sensitif terhadap data pencilan (outlier)</strong></p>
</li>
<li>
<p>Seperti yang telah dijelaskan Ali pada artikel sebelumnya, kNN bisa jadi sangat fleksibel jika k kecil. Fleksibilitas ini mengakibatkan kNN cenderung sensitif terhadap data pencilan, khususnya pencilan yang terletak di “tengah-tengah” kelas yang berbeda. Lebih jelasnya, perhatikan ilustrasi di bawah. Pada gambar kiri, seluruh instance bisa diklasifikasikan dengan benar ke dalam kelas biru dan jingga. Tetapi, ketika ditambahkan instance biru di antara instance jingga, beberapa instance jingga menjadi salah terklasifikasi.Perlu dipilih k yang tepat untuk mengurangi dampak data pencilan dalam kNN.</p>
</li>
</ul>
<p>## Implementasi K-Nearest Neighbor</p>
<p>Langkah-langkah implementasi K-Nearest Neighbor :</p>
<p>Dataset K-Nearset Neighbor "PimaIndians.csv"</p>
<p>##### 1. Mengimportkan library</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
</pre></div>

<p>##### 2. Mengimport dataset </p>
<div class="codehilite"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;PimaIndians.csv&quot;</span><span class="p">)</span>
</pre></div>

<p>##### 3. Menampilkan data yang sudah di masukkan</p>
<div class="codehilite"><pre><span></span><span class="k">print</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
<span class="k">print</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="k">print</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">tail</span><span class="p">())</span>
<span class="k">print</span> <span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
</pre></div>

<p>##### 4. Mengubah nama kolom yang ingin di jadikan kelas karena nama sebelumnya tidak jelas</p>
<div class="codehilite"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span>
    <span class="s1">&#39;test&#39;</span><span class="p">:</span> <span class="s1">&#39;symptom_class&#39;</span>
<span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</pre></div>

<p>##### 5. Membedakan data "positif" dan "negatif"</p>
<div class="codehilite"><pre><span></span><span class="n">positif</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">symptom_class</span> <span class="o">==</span> <span class="s2">&quot;positif&quot;</span><span class="p">]</span>
<span class="n">negatif</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">data</span><span class="o">.</span><span class="n">symptom_class</span> <span class="o">==</span> <span class="s2">&quot;negatif&quot;</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">positif</span><span class="o">.</span><span class="n">insulin</span><span class="p">,</span> <span class="n">positif</span><span class="o">.</span><span class="n">bmi</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;blue&quot;</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;positif&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">negatif</span><span class="o">.</span><span class="n">insulin</span><span class="p">,</span> <span class="n">negatif</span><span class="o">.</span><span class="n">bmi</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s2">&quot;cyan&quot;</span><span class="p">,</span><span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;negatif&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;insulin&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;bmi&quot;</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">())</span>
</pre></div>

<p>##### 6. Kolom symptom_class mempunyai dua nilai kelas yaitu "positif" dan "negatif" dan merupakan data yang akan diklasifikasi</p>
<div class="codehilite"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">symptom_class</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">each</span> <span class="o">==</span> <span class="s2">&quot;positif&quot;</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">symptom_class</span><span class="p">]</span>
</pre></div>

<p>##### 7. Memisahkan data x dan y, y yang akan dijadikan sebagai kolom symptom_class dikarenakan kolom ini yang digunakan untuk klasifikasi dan kolom yang lain akan menjadi nilai x dan menormalisasikan data x</p>
<div class="codehilite"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">symptom_class</span><span class="o">.</span><span class="n">values</span>
<span class="n">x_</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s2">&quot;symptom_class&quot;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x_</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x_</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x_</span><span class="p">)</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">x_</span><span class="p">))</span><span class="o">.</span><span class="n">values</span>
</pre></div>

<p>##### 8. Sebelum menghitung akurasinya, langkah pertama kita bagi menjadi data train dan test , selanjutkan akan menggunakan data latih dan menerapkan pada data uji untuk mengukur akurasi</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span> <span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>

<p>##### 9. Membuat model KNN nya untuk menguji datanya</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">3</span><span class="p">)</span> <span class="c1">#set K neighbor as 3</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted_y</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;KNN accuracy according to K=5 is :&quot;</span><span class="p">,</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>

<p>##### 10. Asumsikan K=5 menjadi yang pertama, jadi loopnya akan berulang 25 kali dan memberikan akurasi pada setiap literasinya sehingga dapat memenuhi nilai K yang optimal</p>
<div class="codehilite"><pre><span></span><span class="n">score_array</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">each</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">25</span><span class="p">):</span>
    <span class="n">knn_loop</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="n">each</span><span class="p">)</span> <span class="c1">#set K neighbor as 3</span>
    <span class="n">knn_loop</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
    <span class="n">score_array</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">knn_loop</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">25</span><span class="p">),</span><span class="n">score_array</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Range&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Score&quot;</span><span class="p">)</span>
<span class="k">print</span> <span class="p">(</span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">())</span>
</pre></div>

<p>##### 11. Jika menggunakan data K=15, maka akan mendapatkan skor maksimal 80%</p>
<div class="codehilite"><pre><span></span><span class="n">knn_final</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span> <span class="c1">#set K neighbor as 15</span>
<span class="n">knn_final</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">predicted_y</span> <span class="o">=</span> <span class="n">knn_final</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;KNN accuracy according to K=15 is :&quot;</span><span class="p">,</span><span class="n">knn_final</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>

<p>## Hasil Implementasi KNN :</p>
<p>#### 1. Tampilan dataset :</p>
<div class="codehilite"><pre><span></span>pregnant     glucose   diastolic     triceps     insulin         bmi  \
count  392.000000  392.000000  392.000000  392.000000  392.000000  392.000000   
mean     3.301020  122.627551   70.663265   29.145408  156.056122   33.086224   
std      3.211424   30.860781   12.496092   10.516424  118.841690    7.027659   
min      0.000000   56.000000   24.000000    7.000000   14.000000   18.200000   
25%      1.000000   99.000000   62.000000   21.000000   76.750000   28.400000   
50%      2.000000  119.000000   70.000000   29.000000  125.500000   33.200000   
75%      5.000000  143.000000   78.000000   37.000000  190.000000   37.100000   
max     17.000000  198.000000  110.000000   63.000000  846.000000   67.100000   

         diabetes         age  
count  392.000000  392.000000  
mean     0.523046   30.864796  
std      0.345488   10.200777  
min      0.085000   21.000000  
25%      0.269750   23.000000  
50%      0.449500   27.000000  
75%      0.687000   36.000000  
max      2.420000   81.000000  
   pregnant  glucose  diastolic  triceps  insulin   bmi  diabetes  age  \
0         1       89         66       23       94  28.1     0.167   21   
1         0      137         40       35      168  43.1     2.288   33   
2         3       78         50       32       88  31.0     0.248   26   
3         2      197         70       45      543  30.5     0.158   53   
4         1      189         60       23      846  30.1     0.398   59   

      test  
0  negatif  
1  positif  
2  positif  
3  positif  
4  positif  
     pregnant  glucose  diastolic  triceps  insulin   bmi  diabetes  age  \
387         0      181         88       44      510  43.3     0.222   26   
388         1      128         88       39      110  36.5     1.057   37   
389         2       88         58       26       16  28.4     0.766   22   
390        10      101         76       48      180  32.9     0.171   63   
391         5      121         72       23      112  26.2     0.245   30   

        test  
387  positif  
388  positif  
389  negatif  
390  negatif  
391  negatif  
         pregnant     glucose   diastolic     triceps     insulin         bmi  \
count  392.000000  392.000000  392.000000  392.000000  392.000000  392.000000   
mean     3.301020  122.627551   70.663265   29.145408  156.056122   33.086224   
std      3.211424   30.860781   12.496092   10.516424  118.841690    7.027659   
min      0.000000   56.000000   24.000000    7.000000   14.000000   18.200000   
25%      1.000000   99.000000   62.000000   21.000000   76.750000   28.400000   
50%      2.000000  119.000000   70.000000   29.000000  125.500000   33.200000   
75%      5.000000  143.000000   78.000000   37.000000  190.000000   37.100000   
max     17.000000  198.000000  110.000000   63.000000  846.000000   67.100000   

         diabetes         age  
count  392.000000  392.000000  
mean     0.523046   30.864796  
std      0.345488   10.200777  
min      0.085000   21.000000  
25%      0.269750   23.000000  
50%      0.449500   27.000000  
75%      0.687000   36.000000  
max      2.420000   81.000000  
</pre></div>

<p>#### 2. Tampilan Plot K=5 :</p>
<p><img alt="" src="../assets/images/titik.PNG" /></p>
<p>#### 3. Tampilan Plot K=15 :</p>
<p><img alt="" src="../assets/images/mahrus.PNG" /></p>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href=".." title="Penjelasan tentang K-Means Clustering" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                Penjelasan tentang K-Means Clustering
              </span>
            </div>
          </a>
        
        
          <a href="../customization/" title="Penjelasan tentang Decision Tree Classifier" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                Penjelasan tentang Decision Tree Classifier
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
          <div class="md-footer-copyright__highlight">
            Copyright &copy; 2019 Mahrus Sholeh
          </div>
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../assets/fonts/font-awesome.css">
    
      <a href="https://github.com/MahrusSholeh" class="md-footer-social__link fa fa-github-alt"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/application.8c0d971c.js"></script>
      
      <script>app.initialize({version:"1.0.4",url:{base:".."}})</script>
      
    
  </body>
</html>